> [!note]
> æœ¬æ•™ç¨‹æ¼”ç¤ºå¦‚ä½•é€šè¿‡ **Python** å®ç° Hadoop Shell çš„å¸¸è§æ–‡ä»¶æ“ä½œï¼ŒåŒ…æ‹¬ä¸Šä¼ ã€ä¸‹è½½ã€æŸ¥çœ‹ã€åˆ é™¤ã€ç§»åŠ¨ç­‰ã€‚
> éœ€ç¡®ä¿å·²æ­£ç¡®é…ç½® `HADOOP_HOME` ç¯å¢ƒå˜é‡ã€‚
> [Hadoopä¼ªåˆ†å¸ƒå¼å®‰è£…](../lab1/PseudoDistributed.md)


---

ä½¿ç”¨pythonæ“æ§hdfséœ€è¦é¢„å®‰è£…hdfsä¾èµ–
```bash
sudo apt install pip python3.12-venv
# ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ(ubuntu22.04ä»¥ä¸Šå¿…é¡»)
python3 -m venv venv
source venv/bin/activate
# å®‰è£…hdfsä¾èµ–
pip install hdfs -i https://pypi.tuna.tsinghua.edu.cn/simple
```

ä½¿ç”¨`python3 .pyæ–‡ä»¶`å³å¯è¿è¡Œ

## â‘  ä¸Šä¼ æ–‡ä»¶åˆ° HDFSï¼ˆè¿½åŠ æˆ–è¦†ç›–ï¼‰

**upload_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys
import os

# å‚æ•°è¯´æ˜ï¼š
# sys.argv[1] -> æœ¬åœ°æ–‡ä»¶è·¯å¾„
# sys.argv[2] -> HDFS ç›®æ ‡è·¯å¾„
# sys.argv[3] -> æ˜¯å¦è¿½åŠ ï¼ˆTrue/Falseï¼‰

def upload_file(local_path, hdfs_path, append):
    client = InsecureClient('http://localhost:9870', user='hadoop')  # ä¿®æ”¹ä¸ºä½ çš„ HDFS web åœ°å€
    if client.status(hdfs_path, strict=False):
        if append:
            # HDFS ä¸æ”¯æŒç›´æ¥åœ¨åŸæ–‡ä»¶å¼€å¤´å†™å…¥ï¼Œåªèƒ½è¿½åŠ 
            with open(local_path, 'rb') as f:
                data = f.read()
            client.write(hdfs_path, data, append=True)
        else:
            client.upload(hdfs_path, local_path, overwrite=True)
    else:
        client.upload(hdfs_path, local_path)
    print("âœ… ä¸Šä¼ å®Œæˆï¼š", hdfs_path)

if __name__ == "__main__":
    upload_file(sys.argv[1], sys.argv[2], sys.argv[3].lower() == 'true')
```

**Shell å‘½ä»¤ï¼š**

```bash
# è¦†ç›–ä¸Šä¼ 
hdfs dfs -put -f æœ¬åœ°æ–‡ä»¶ HDFSç›®æ ‡è·¯å¾„

# è¿½åŠ ä¸Šä¼ 
hdfs dfs -appendToFile æœ¬åœ°æ–‡ä»¶ HDFSç›®æ ‡è·¯å¾„
```

---

## â‘¡ ä» HDFS ä¸‹è½½æ–‡ä»¶ï¼ˆè‡ªåŠ¨é‡å‘½åï¼‰

**download_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys
import os

# sys.argv[1] -> HDFS æ–‡ä»¶è·¯å¾„
# sys.argv[2] -> æœ¬åœ°ä¿å­˜è·¯å¾„

def download_file(hdfs_file, local_file):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    if os.path.exists(local_file):
        local_file = local_file + "_new"

    client.download(hdfs_file, local_file, overwrite=True)
    print("âœ… ä¸‹è½½å®Œæˆï¼š", local_file)

if __name__ == "__main__":
    download_file(sys.argv[1], sys.argv[2])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -get HDFSæ–‡ä»¶è·¯å¾„ æœ¬åœ°è·¯å¾„
mv æœ¬åœ°è·¯å¾„ æœ¬åœ°è·¯å¾„_new
```

---

## â‘¢ è¾“å‡º HDFS æ–‡ä»¶å†…å®¹åˆ°ç»ˆç«¯

**cat_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys

# sys.argv[1] -> HDFS æ–‡ä»¶è·¯å¾„

def cat_file(hdfs_file):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    with client.read(hdfs_file, encoding='utf-8') as reader:
        print(reader.read())

if __name__ == "__main__":
    cat_file(sys.argv[1])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -cat HDFSæ–‡ä»¶è·¯å¾„
```

---

## â‘£ æ˜¾ç¤ºæ–‡ä»¶å±æ€§

**file_info_hdfs.py**

```python
from hdfs import InsecureClient
import sys
import time

# sys.argv[1] -> HDFS æ–‡ä»¶è·¯å¾„

def file_info(hdfs_file):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    status = client.status(hdfs_file)

    print("æƒé™:", status['permission'])
    print("å¤§å°:", status['length'])
    print("ä¿®æ”¹æ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(status['modificationTime']/1000)))
    print("è·¯å¾„:", status['pathSuffix'])

if __name__ == "__main__":
    file_info(sys.argv[1])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -ls -d HDFSæ–‡ä»¶è·¯å¾„
```

---

## â‘¤ é€’å½’è¾“å‡ºç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å±æ€§

**list_dir_hdfs.py**

```python
from hdfs import InsecureClient
import sys

# sys.argv[1] -> HDFS ç›®å½•è·¯å¾„

def list_dir(hdfs_dir):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    def recurse(path):
        for item in client.list(path, status=True):
            info = item[1]
            print(f"{path}/{item[0]} æƒé™:{info['permission']} å¤§å°:{info['length']}")
            if info['type'] == 'DIRECTORY':
                recurse(f"{path}/{item[0]}")

    recurse(hdfs_dir)

if __name__ == "__main__":
    list_dir(sys.argv[1])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -ls -R HDFSç›®å½•è·¯å¾„
```

---

## â‘¥ åˆ›å»ºæˆ–åˆ é™¤æ–‡ä»¶ï¼ˆè‡ªåŠ¨åˆ›å»ºç›®å½•ï¼‰

**create_delete_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys
import os

# sys.argv[1] -> æ–‡ä»¶è·¯å¾„
# sys.argv[2] -> True åˆ›å»º / False åˆ é™¤

def create_delete_file(hdfs_path, create):
    client = InsecureClient('http://localhost:9870', user='hadoop')

    if create:
        parent = os.path.dirname(hdfs_path)
        if not client.status(parent, strict=False):
            client.makedirs(parent)
        client.write(hdfs_path, b"", overwrite=True)
        print("âœ… æ–‡ä»¶å·²åˆ›å»ºï¼š", hdfs_path)
    else:
        client.delete(hdfs_path)
        print("ğŸ—‘ï¸ æ–‡ä»¶å·²åˆ é™¤ï¼š", hdfs_path)

if __name__ == "__main__":
    create_delete_file(sys.argv[1], sys.argv[2].lower() == 'true')
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -mkdir -p /dir1/dir2
hdfs dfs -touchz /dir1/dir2/file.txt
hdfs dfs -rm /dir1/dir2/file.txt
```

---

## â‘¦ åˆ›å»ºæˆ–åˆ é™¤ç›®å½•ï¼ˆé€’å½’ï¼‰

**create_delete_dir_hdfs.py**

```python
from hdfs import InsecureClient
import sys

# sys.argv[1] -> ç›®å½•è·¯å¾„
# sys.argv[2] -> True åˆ›å»º / False åˆ é™¤
# sys.argv[3] -> åˆ é™¤æ—¶æ˜¯å¦é€’å½’ï¼ˆå¯é€‰ï¼‰

def create_delete_dir(hdfs_dir, create, recursive=False):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    if create:
        client.makedirs(hdfs_dir)
        print("âœ… ç›®å½•å·²åˆ›å»ºï¼š", hdfs_dir)
    else:
        client.delete(hdfs_dir, recursive=recursive)
        print("ğŸ—‘ï¸ ç›®å½•å·²åˆ é™¤ï¼š", hdfs_dir)

if __name__ == "__main__":
    recursive = len(sys.argv) > 3 and sys.argv[3].lower() == 'true'
    create_delete_dir(sys.argv[1], sys.argv[2].lower() == 'true', recursive)
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -mkdir -p /dir1/dir2
hdfs dfs -rm -r /dir1/dir2
```

---

## â‘§ è¿½åŠ æ–‡ä»¶å†…å®¹ï¼ˆå¼€å¤´æˆ–ç»“å°¾ï¼‰

**append_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys
import tempfile

# sys.argv[1] -> HDFS æ–‡ä»¶è·¯å¾„
# sys.argv[2] -> æœ¬åœ°å†…å®¹æ–‡ä»¶
# sys.argv[3] -> True è¿½åŠ åˆ°ç»“å°¾ / False è¿½åŠ åˆ°å¼€å¤´

def append_file(hdfs_file, content_file, append_to_end):
    client = InsecureClient('http://localhost:9870', user='hadoop')

    with open(content_file, 'rb') as f:
        new_data = f.read()

    if append_to_end:
        client.write(hdfs_file, new_data, append=True)
    else:
        # å…ˆä¸‹è½½æ—§æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            client.download(hdfs_file, tmp.name, overwrite=True)
            with open(tmp.name, 'rb') as old:
                old_data = old.read()
        # è¦†ç›–å†™å…¥æ–°å†…å®¹+æ—§å†…å®¹
        client.write(hdfs_file, new_data + old_data, overwrite=True)
    print("âœ… æ–‡ä»¶å†…å®¹è¿½åŠ æˆåŠŸ")

if __name__ == "__main__":
    append_file(sys.argv[1], sys.argv[2], sys.argv[3].lower() == 'true')
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -appendToFile æœ¬åœ°æ–‡ä»¶ HDFSæ–‡ä»¶è·¯å¾„
```

---

## â‘¨ åˆ é™¤æ–‡ä»¶

**delete_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys

# sys.argv[1] -> HDFS æ–‡ä»¶è·¯å¾„

def delete_file(hdfs_file):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    client.delete(hdfs_file)
    print("ğŸ—‘ï¸ æ–‡ä»¶å·²åˆ é™¤ï¼š", hdfs_file)

if __name__ == "__main__":
    delete_file(sys.argv[1])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -rm HDFSæ–‡ä»¶è·¯å¾„
```

---

## â‘© ç§»åŠ¨æ–‡ä»¶

**move_file_hdfs.py**

```python
from hdfs import InsecureClient
import sys

# sys.argv[1] -> æºæ–‡ä»¶è·¯å¾„
# sys.argv[2] -> ç›®æ ‡è·¯å¾„

def move_file(src_path, dst_path):
    client = InsecureClient('http://localhost:9870', user='hadoop')
    client.rename(src_path, dst_path)
    print(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨ï¼š{src_path} -> {dst_path}")

if __name__ == "__main__":
    move_file(sys.argv[1], sys.argv[2])
```

**Shell å‘½ä»¤ï¼š**

```bash
hdfs dfs -mv /æºè·¯å¾„ /ç›®æ ‡è·¯å¾„
```
