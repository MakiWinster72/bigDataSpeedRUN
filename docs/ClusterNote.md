## å®éªŒè®¾å¤‡

### ç¡¬ä»¶

| è®¾å¤‡å             | æ•°é‡ | å¤‡æ³¨                             |
| ------------------ | ---- | -------------------------------- |
| è®¡ç®—æœº<br>         | 4    | æˆå‘˜è®¾å¤‡ï¼Œç”¨äºè¿è¡Œ ubuntu è™šæ‹Ÿæœº |
| è·¯ç”±å™¨ï¼šHUAWEI AX6 | 1    | é€šä¿¡è®¾å¤‡ï¼Œç”¨äºä¸ºå„ä¸»æœºå»ºç«‹è¿æ¥   |

> å•è®¡ç®—æœºå¤šè™šæ‹Ÿæœºä¹Ÿå¯ä»¥ï¼ŒæœåŠ¡å™¨ä¹Ÿå¯ä»¥ï¼Œå…¨æœåŠ¡å™¨ä¹Ÿå¯ä»¥ã€‚æ ¸å¿ƒæ˜¯é€šè¿‡ipé€šä¿¡ï¼ŒæœåŠ¡å™¨å»ºè®®å„ä¸»æœºåœ¨åŒä¸€ä¸ªvpsç½‘ç»œä¸­ã€‚

### è½¯ä»¶

| è½¯ä»¶åç§°      | ç‰ˆæœ¬        |
| ------------- | ----------- |
| Ubuntu è™šæ‹Ÿæœº | 24.04.4 LTS |
| Hadoop        | 3.4.2       |
| HBase         | 2.6.3       |
| Hive          | 4.2.0       |
| Zookeeper     | 3.8.5       |
| Spark         | 4.0.1       |
| Scala         | 2.13.16     |
| OpenJDK       | 21          |

## å®éªŒæ­¥éª¤

### ç¯å¢ƒå‡†å¤‡

#### å…è®¸ hadoop å…å¯†ç  sudo

> ä¸»è¦ä¸ºäº†åç»­ master å¯ç›´æ¥è¿œç¨‹ ssh Slaves ä¸»æœºæ—¶ä½¿ç”¨sudoæ— éœ€å¯†ç ã€‚
> ä¹Ÿå¯é€‰æ‹©é…ç½®å…è®¸è¿œç¨‹ root ç™»å½•

åœ¨ master å’Œ slave1 ï½ 3 éƒ½æ‰§è¡Œ

```bash
sudo visudo
```

ä¼šç”¨ nano ç¼–è¾‘ sudoers
æ–°å¢ä¸€è¡Œ

```
hadoop ALL=(ALL) NOPASSWD: ALL
```

![](https://img.makis-life.cn/images/20251210053415876.png?x-oss-process=style/yasuo)

#### é€šä¿¡

å››å°ä¸»æœºå…¨éƒ¨æ¥å…¥è·¯ç”±å™¨ï¼Œå³å‡å¤„äºåŒä¸€å±€åŸŸç½‘ä¸­ï¼Œä»è€Œå®ç°ä¸»æœºé—´é€šä¿¡ã€‚

ä»¤è™šæ‹Ÿæœºå¤„äºæ¡¥æ¥æ¨¡å¼ï¼Œåœ¨ Ubuntu ä¸­ä½¿ç”¨ `ip addr show` æŸ¥çœ‹ ip åœ°å€

ä¾‹å¦‚ï¼š

![](https://img.makis-life.cn/images/20251210053415878.png?x-oss-process=style/yasuo)

<center>æ£€æŸ¥ Master çš„ IP åœ°å€</center>

å…¶ä¸­ enp0s3 æ˜¯å½“å‰æ‰€ä½¿ç”¨çš„ç½‘å¡ï¼Œå¯çŸ¥ç›®å‰ ipv4 åœ°å€ä¸º 192.168.1.101ã€‚

è·å–åˆ°å››å°è™šæ‹Ÿæœºçš„ IP åœ°å€å¦‚ä¸‹

| ä¸»æœº   | IPv4          |
| ------ | ------------- |
| Master | 192.168.1.104 |
| Slave1 | 192.168.1.102 |
| Slave2 | 192.168.1.101 |
| Slave3 | 192.168.1.105 |

##### æ£€æŸ¥è¿é€šæ€§

è™šæ‹Ÿæœºé—´äº’ pingï¼Œæ£€éªŒä¸åŒä¸»æœºé—´è™šæ‹Ÿæœºæ˜¯å¦å¯ä»¥æ­£å¸¸é€šä¿¡

1. ç™»å½• master

```
ssh hadoop@192.168.1.104
ping 192.168.1.102 -c 3
ping 192...ï¼ˆå„ Slaves çš„ipåœ°å€ï¼‰
```

![](https://img.makis-life.cn/images/20251210053415879.png?x-oss-process=style/yasuo)

#### ç¼–è¾‘ hosts æ–‡ä»¶

```bash
sudo nvim /etc/hosts
```

![](https://img.makis-life.cn/images/20251210053415880.png?x-oss-process=style/yasuo)

å°† hosts æ–‡ä»¶ä¼ é€’ç»™å„ä¸»æœº

```bash
scp /etc/hosts hadoop@master:~
scp /etc/hosts hadoop@slave1:ï½
...
```

![](https://img.makis-life.cn/images/20251210053415881.png?x-oss-process=style/yasuo)

#### è®¾ç½®ä¸»æœºå

```bash
sudo hostnamectl set-hostname master
```

![](https://img.makis-life.cn/images/20251210053415882.png?x-oss-process=style/yasuo)

<center>Master è®¾ç½®ä¸»æœºå</center>

å¯è§ï¼Œå†æ¬¡è¾“å…¥`bash`ï¼Œå³åˆ·æ–°å½“å‰ SHELLï¼Œå¯ä»¥çœ‹è§å‰é¢å·²ç»å˜ä¸º hadoop@masterï¼Œæ–¹ä¾¿è¾¨è®¤ master å’Œ slaves

æ›´æ”¹å„ä¸»æœºå
![](https://img.makis-life.cn/images/20251210053415883.png?x-oss-process=style/yasuo)
é€šè¿‡ ssh ä¸ºå„ä¸»æœºæ‰§è¡Œå‘½ä»¤
æ­¤å¤„ sudo å·²ç»ä¸å†éœ€è¦å¯†ç ï¼Œå› ä¸ºç¬¬ä¸€æ­¥å·²ç»å…è®¸ hadoop ç”¨æˆ·å…å¯†ç æ‰§è¡Œ sudo æƒé™æŒ‡ä»¤

#### run.sh è„šæœ¬

> å¯è§ä¸Šè¿°ç»å¸¸æœ‰ ssh æˆ– scp æ­¥éª¤ï¼Œå¯¹äº slave1/slave2/slave3 æ˜¯å®Œå…¨ä¸€è‡´çš„ï¼Œä¸ºå‡å°‘é‡å¤çš„æŒ‡ä»¤è¾“å…¥ï¼Œæˆ‘ä»¬å†™äº†ä¸€ä¸ª sh è„šæœ¬ï¼š

```sh
#!/bin/bash

# å®šä¹‰æ‰€æœ‰ slave
SLAVES=("slave1" "slave2" "slave3")

TARGET=$1 # slaves æˆ–è€…å…·ä½“æŸä¸ª slave
ACTION=$2 # ssh / scp
shift 2   # å»æ‰å‰ä¸¤ä¸ªå‚æ•°ï¼Œå‰©ä¸‹çš„æ˜¯å‘½ä»¤æˆ–è·¯å¾„

if [ "$TARGET" == "slaves" ]; then
  HOSTS=("${SLAVES[@]}")
else
  HOSTS=("$TARGET")
fi

for HOST in "${HOSTS[@]}"; do
  echo "æ­£åœ¨å¤„ç† $HOST ..."

  if [ "$ACTION" == "ssh" ]; then
    # ç»„åˆå‰©ä½™å‚æ•°ä¸ºå‘½ä»¤
    CMD="$*"
    # ä½¿ç”¨ç™»å½• shell (-l) æ‰§è¡Œå‘½ä»¤
    ssh -t hadoop@"$HOST" "bash -l -c '$CMD'"
  elif [ "$ACTION" == "scp" ]; then
    # scp å‘½ä»¤éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼šæœ¬åœ°æ–‡ä»¶/ç›®å½• å’Œ è¿œç¨‹è·¯å¾„
    LOCAL="$1"
    REMOTE="$2"
    scp -rq "$LOCAL" hadoop@"$HOST":"$REMOTE"
  else
    echo "ä¸æ”¯æŒçš„æ“ä½œ: $ACTION"
  fi

  echo "$HOST å®Œæˆ"
done
```

ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¦åœ¨ slave1 å’Œ 2 å’Œ 3 ä¸Šåˆ›å»º/usr/lib/jvm æ–‡ä»¶å¤¹ï¼Œåªéœ€è¦

```bash
./run.sh slaves ssh "sudo mkdir /usr/lib/jvm"
```

å³å¯ã€‚

### é…ç½® ssh å…å¯†ç ç™»å½•

hadoop é›†ç¾¤éœ€è¦ ssh å…å¯†ç ç™»å½•æ‰å¯æ­£å¸¸è¿è¡Œ

> å¹¶ä¸”ä¸Šè¿°å¯è§ï¼Œå³ä½¿å·²ç»é…ç½®äº† hadoop å…å¯† sudo æƒé™ï¼Œä½†æ˜¯è¿œç¨‹ç™»å½•ä¾ç„¶éœ€è¦å¯†ç ï¼ŒSlaves å¤šäº†éå¸¸éº»çƒ¦ã€‚é…ç½® ssh å…å¯†ç ç™»å½•å¯å‡å°‘è¾“å…¥å¯†ç çš„æ­¥éª¤ã€‚

#### åœ¨ master èŠ‚ç‚¹æ‰§è¡Œ

```bash
# ç”Ÿæˆå¯†é’¥å¯¹
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
```

![](https://img.makis-life.cn/images/20251210053415884.png?x-oss-process=style/yasuo)

#### åˆ†å‘å¯†é’¥

```bash
# å¤åˆ¶å…¬é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
ssh-copy-id -i ~/.ssh/id_rsa.pub master
ssh-copy-id -i ~/.ssh/id_rsa.pub slave1
ssh-copy-id -i ~/.ssh/id_rsa.pub slave2
ssh-copy-id -i ~/.ssh/id_rsa.pub slave3
```

ä¼šä¾æ¬¡è¯¢é—®æ˜¯å¦æ·»åŠ ä¸»æœºä»¥åŠå¯¹åº”ä¸»æœºçš„å¯†ç ã€‚
![](https://img.makis-life.cn/images/20251210053415885.png?x-oss-process=style/yasuo)

```bash
# æµ‹è¯•å…å¯†ç™»å½•
ssh master
ssh slave1
ssh slave2
ssh slave3
```

å¯è§ç°åœ¨ ssh slave1 å·²ç»ä¸å†éœ€è¦è¾“å…¥å¯†ç ï¼Œå…ç™»å½•è®¾ç½®æˆåŠŸã€‚
![](https://img.makis-life.cn/images/20251210053415886.png?x-oss-process=style/yasuo)

### å®‰è£… Java

#### ä¸‹è½½

å‰å¾€[åä¸º Openjdk](https://mirrors.huaweicloud.com/openjdk/)
æˆ– wget ä¸‹è½½

```bash
wget https://mirrors.huaweicloud.com/openjdk/21/openjdk-21_linux-x64_bin.tar.gz
```

#### å®‰è£…

```bash
tar -xzf openjdk(æŒ‰ä¸‹tab)
sudo mkdir /usr/lib/jvm
sudo mv jdk-21 /usr/lib/jvm/jdk21   # å¸¸è§jdkéƒ½å®‰è£…åœ¨è¿™é‡Œï¼Œä¹Ÿå¯è‡ªå·±é€‰å®šåœ°æ–¹
```

ç¼–è¾‘`~/.profile`æ–‡ä»¶ï¼Œå†™å…¥ JAVA_HOME

```bash
# JAVA
export JAVA_HOME=/usr/lib/jvm/jdk21
export PATH=$JAVA_HOME/bin:$PATH
```

![](https://img.makis-life.cn/images/20251210053415887.png?x-oss-process=style/yasuo)

æ£€éªŒ java æ˜¯å¦å®‰è£…æˆåŠŸ
![](https://img.makis-life.cn/images/20251210053415888.png?x-oss-process=style/yasuo)

#### åˆ†å‘ java å¹¶å®‰è£…

```bash
./run.sh slaves scp /usr/lib/jvm/jdk21 ~   # åˆ†å‘jdk21åˆ°ç”¨æˆ·homeç›®å½•
./run.sh slaves ssh "sudo mkdir -p /usr/lib/jvm"  # åˆ›å»ºjvmæ–‡ä»¶å¤¹
./run.sh slaves ssh "sudo mv ~/jdk21 /usr/lib/jvm/jdk21"  # ç§»åŠ¨jdk21åˆ°jvmç›®å½•
./run.sh slaves scp ~/.profile ~/.profile  # åˆ†å‘.profileæ–‡ä»¶
```

æ£€æŸ¥å„ä¸ªä¸»æœºæ˜¯å¦æˆåŠŸå®‰è£… java
![](https://img.makis-life.cn/images/20251210053415889.png?x-oss-process=style/yasuo)

### å®‰è£… zookeeper

#### ä¸‹è½½

å‰å¾€[é˜¿é‡Œäº‘é•œåƒç«™](https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.8.5/?spm=a2c6h.25603864.0.0.53226961zXU2VX)æˆ– wget ä¸‹è½½

```bash
wget https://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.8.5/apache-zookeeper-3.8.5-bin.tar.gz
```

å°†æœ¬åœ° zookeeper å®‰è£…åŒ…å‘é€ç»™ master

```bash
scp å®‰è£…åŒ…è·¯å¾„ hadoop@master:~   # Windows ä½¿ç”¨winscp
```

![](https://img.makis-life.cn/images/20251210053415890.png?x-oss-process=style/yasuo)

åœ¨ master ä¸Šå®‰è£… zookeeper

```bash
tar -xzf apac(æŒ‰ä¸‹tab)
sudo mv apac(æŒ‰ä¸‹tab) /usr/local/zookeeper
sudo chown -R hadoop:hadoop /usr/local/zookeeper   # æ”¹å˜æ–‡ä»¶æ‰€å±ç”¨æˆ·
```

> [!warning]
> å¦‚æœä½ çš„ç”¨æˆ·ä¸å« hadoopï¼Œå¯ä»¥ç”¨`whoami`å¾—çŸ¥ç”¨æˆ·åï¼Œå½“ç„¶ï¼Œå¯ä»¥æŠŠä¸Šè¿°æŒ‡ä»¤æ¢æˆ
> sudo chown -R $(whoami):$(whoami) /usr/local/zookeeper

![](https://img.makis-life.cn/images/20251210053415891.png?x-oss-process=style/yasuo)

åˆ›å»ºå·¥ä½œç›®å½•

```bash
sudo mkdir -p /usr/local/zookeeper/data
sudo mkdir -p /usr/local/zookeeper/logs
```

#### é…ç½® ZooKeeper

![](https://img.makis-life.cn/images/20251210053415892.png?x-oss-process=style/yasuo)

ä¿®æ”¹å†…å®¹:

```properties
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/usr/local/zookeeper/data
dataLogDir=/usr/local/zookeeper/logs
clientPort=2181

# é›†ç¾¤é…ç½®
server.1=master:2888:3888
server.2=slave1:2888:3888
server.3=slave2:2888:3888
server.4=slave3:2888:3888
```

![](https://img.makis-life.cn/images/20251210053415893.png?x-oss-process=style/yasuo)

#### åˆ†å‘ ZooKeeper åˆ° Slave èŠ‚ç‚¹

```bash
./run.sh scp /usr/local/zookeeper ~
```

#### Slaves èŠ‚ç‚¹å®‰è£… ZooKeeper

![](https://img.makis-life.cn/images/20251210053415894.png?x-oss-process=style/yasuo)

è®¾ç½®å„èŠ‚ç‚¹çš„ myid
master -> 1, Slave1 -> 2, Slave2 -> 3, Slave3 -> 4

```bash
./run.sh slaves ssh "cat /usr/local/zookeeper/data/myid"
```

![](https://img.makis-life.cn/images/20251210053415895.png?x-oss-process=style/yasuo)

æ£€éªŒæ˜¯å¦é…ç½®æˆåŠŸ
![](https://img.makis-life.cn/images/20251210053415896.png?x-oss-process=style/yasuo)

#### æ›´æ–°ç¯å¢ƒå˜é‡

ç¼–è¾‘`~/.profile`
![](https://img.makis-life.cn/images/20251210053415897.png?x-oss-process=style/yasuo)
åˆ†å‘`~/.profile`

```bash
./run.sh slaves scp ~/.profile ~/.profile
```

![](https://img.makis-life.cn/images/20251210053415898.png?x-oss-process=style/yasuo)

#### å¯åŠ¨ zookeeper

```bash
zkServer.sh start
```

![](https://img.makis-life.cn/images/20251210053415899.png?x-oss-process=style/yasuo)

#### æ£€æŸ¥ ZooKeeper é›†ç¾¤çŠ¶æ€

```bash
zkServer.sh status
```

![](https://img.makis-life.cn/images/20251210053415900.png?x-oss-process=style/yasuo)
å¯ä»¥çœ‹è§ï¼ŒSlave2 è¢«é€‰ä¸­æˆä¸º leader,å…¶ä½™ä¸º followerã€‚

> [!note] ğŸ‰
> è‡³æ­¤ï¼Œzookeeper é›†ç¾¤æ­å»ºå®Œæˆã€‚

### å®‰è£… Hadoop é›†ç¾¤

#### å°†æœ¬åœ° hadoop å®‰è£…åŒ…å‘é€ç»™ master

```bash
scp hadoop-3.4.2.tar.gz hadoop@master:~
```

#### master å®‰è£… hadoop

![](https://img.makis-life.cn/images/20251210053415901.png?x-oss-process=style/yasuo)

#### åˆ›å»ºå·¥ä½œç¯å¢ƒ

```bash
sudo mkdir -p /usr/local/hadoop/tmp
sudo mkdir -p /usr/local/hadoop/hdfs/name
sudo mkdir -p /usr/local/hadoop/hdfs/data
sudo chown -R $USER:$USER /usr/local/hadoop
```

#### é…ç½® Hadoop ç¯å¢ƒ

ç¼–è¾‘`~/.profile`ï¼Œæ–°å¢ï¼š

```profile
# HADOOP
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
```

ç›®å‰ `~/.profile` çŠ¶æ€
![](https://img.makis-life.cn/images/20251210053415902.png?x-oss-process=style/yasuo)

#### é…ç½® Hadoop å„ç»„ä»¶

| ç»„ä»¶å    | é…ç½®æ–‡ä»¶å      |
| --------- | --------------- |
| common    | core-site.xml   |
| HDFS      | hdfs-site.xml   |
| MapReduce | mapred-site.xml |
| YARN      | yarn-site.xml   |

```bash
cd $HADOOP_HOME/etc/hadoop
nvim hadoop-env.sh
```

æ‰¾åˆ°`export JAVA_HOME=`è¡Œï¼Œè‹¥ä½¿ç”¨ vim å¯ä½¿ç”¨/è¿›å…¥æœç´¢æ¨¡å¼
![](https://img.makis-life.cn/images/20251210053415903.png?x-oss-process=style/yasuo)
åŒæ ·ï¼Œç¼–è¾‘`yarn-env.sh`æ·»åŠ  JAVA_HOMEï¼Œè‹¥æ‰¾ä¸åˆ° JAVA_HOME è¡Œåˆ™æ–°å¢å³å¯

#### é…ç½® core-site.xml

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop/tmp</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>root</value>
    </property>
</configuration>
```

#### é…ç½® hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/hdfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/hdfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>master:9870</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:9868</value>
    </property>
</configuration>

```

#### é…ç½® yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME,HADOOP_HOME,PATH</value>
    </property>
</configuration>
```

#### é…ç½® mapred-site.xml

```xml
<configuration>
    <property>
        <!--æŒ‡å®šMapreduceè¿è¡Œåœ¨yarnä¸Š-->
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
</configuration>
```

#### **é…ç½® workers æ–‡ä»¶:**

```bash
vim $HADOOP_HOME/etc/hadoop/workers
```

å†…å®¹:

```
slave1
slave2
slave3
```

#### æ›´æ–°ç¯å¢ƒå˜é‡ï¼Œåˆ†å‘ hadoop

```bash
./run.sh slaves scp ~/.profile ~/.profile    # åˆ†å‘profile
./run.sh slaves ssh "source ~/.profile && echo $HADOOP_HOME"  # æ£€æŸ¥æ˜¯å¦åˆ†å‘æˆåŠŸ
./run.sh slaves scp /usr/local/hadoop ~   # åˆ†å‘hadoop
./run.sh slaves ssh "sudo mv ~/hadoop /usr/local/hadoop"  # ç§»åŠ¨åˆ°/usr/localæ–‡ä»¶å¤¹
```

![](https://img.makis-life.cn/images/20251210053415904.png?x-oss-process=style/yasuo)
![](https://img.makis-life.cn/images/20251210053415905.png?x-oss-process=style/yasuo)

#### æ ¼å¼åŒ– namenode

åœ¨ master ä¸Š

```bash
hadoop namenode -format
```

![](https://img.makis-life.cn/images/20251210053415906.png?x-oss-process=style/yasuo)
![](https://img.makis-life.cn/images/20251210053415907.png?x-oss-process=style/yasuo)

#### åœ¨ master ä¸­å¯åŠ¨ hadoop

```bash
start-dfs.sh
start-yarn.sh

# æˆ– start-all.sh ï¼ˆå·²è¿‡æ—¶ï¼‰
```

![](https://img.makis-life.cn/images/20251210053415908.png?x-oss-process=style/yasuo)

#### æ£€æŸ¥å„èŠ‚ç‚¹ jps

master
![](https://img.makis-life.cn/images/20251210053415909.png?x-oss-process=style/yasuo)

slaves
![](https://img.makis-life.cn/images/20251210053415910.png?x-oss-process=style/yasuo)

#### è®¿é—® hadoopWeb

æµè§ˆå™¨è®¿é—® <http://master:9870> ï¼ŒæŸ¥çœ‹ datanode
![](https://img.makis-life.cn/images/20251210053415911.png?x-oss-process=style/yasuo)
å¯ä»¥çœ‹è§ Slaves ä»¬çš„æ•°æ®ã€‚

> [!note] ğŸ‰
> è‡³æ­¤ï¼Œhadoop é›†ç¾¤æ­å»ºæˆåŠŸã€‚

### å®‰è£… HBase é›†ç¾¤

#### ä¸‹è½½

å‰å¾€[é˜¿é‡Œäº‘é•œåƒç«™](https://mirrors.aliyun.com/apache/hbase/)æˆ– wget ä¸‹è½½

```bash
wget https://mirrors.aliyun.com/apache/hbase/2.6.4/hbase-2.6.4-bin.tar.gz
```

å°† hbase å®‰è£…åŒ…å‘é€åˆ° master ä¸Š
![](https://img.makis-life.cn/images/20251210053415912.png?x-oss-process=style/yasuo)

#### å®‰è£…

è§£å‹å¹¶å®‰è£… hbase
![](https://img.makis-life.cn/images/20251210053415913.png?x-oss-process=style/yasuo)
ç¼–è¾‘ hbase-env.sh

```bash
nvim /usr/local/hbase/conf/hbase.env.sh
```

æŸ¥æ‰¾æˆ–ç›´æ¥åœ¨æ–‡ä»¶å¤´æ–°å¢ä»¥ä¸‹å››è¡Œ

```bash
export HBASE_MANAGES_ZK=false
export JAVA_HOME=/usr/lib/jvm/jdk21
export HBASE_CLASSPATH=/usr/local/hadoop/etc/hadoop
export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
```

![](https://img.makis-life.cn/images/20251210053415914.png?x-oss-process=style/yasuo)
**å¤åˆ¶ Hadoop é…ç½®æ–‡ä»¶:**

```bash
cp $HADOOP_HOME/etc/hadoop/core-site.xml $HBASE_HOME/conf/
cp $HADOOP_HOME/etc/hadoop/hdfs-site.xml $HBASE_HOME/conf/
```

**é…ç½® hbase-site.xml:**

```bash
vim $HBASE_HOME/conf/hbase-site.xml
```

å†…å®¹:

```xml
<configuration>
    <property>
        <name>hbase.rootdir</name>
        <value>hdfs://master:9000/hbase</value>
    </property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.zookeeper.quorum</name>
    <!-- è¿™é‡Œå¯¹åº”å¥½Slavesçš„æ•°é‡ -->
        <value>master,slave1,slave2,slave3</value>
    </property>
    <property>
        <name>hbase.zookeeper.property.dataDir</name>
        <value>/usr/local/zookeeper/data</value>
    </property>
    <property>
        <name>hbase.zookeeper.property.clientPort</name>
        <value>2181</value>
    </property>
    <property>
        <name>hbase.unsafe.stream.capability.enforce</name>
        <value>false</value>
    </property>
    <property>
        <name>hbase.master.info.port</name>
        <value>16010</value>
    </property>
</configuration>
```

**é…ç½® regionservers:**

```bash
vim $HBASE_HOME/conf/regionservers
```

å†…å®¹:
![](https://img.makis-life.cn/images/20251210053415915.png?x-oss-process=style/yasuo)

#### åˆ†å‘ HBase

```bash
./run.sh slaves scp /usr/local/hbase ~
```

![](https://img.makis-life.cn/images/20251210053415916.png?x-oss-process=style/yasuo)

å®‰è£… hbase åˆ°`/usr/local/hbase`
![](https://img.makis-life.cn/images/20251210053415917.png?x-oss-process=style/yasuo)

#### åˆ†å‘ profile å¹¶æ£€æŸ¥

![](https://img.makis-life.cn/images/20251210053415918.png?x-oss-process=style/yasuo)

#### å¯åŠ¨ HBase

ç¡®ä¿ hadoop å’Œ zookeeper å·²ç»å¼€å¯ã€‚

```
start-hbase.sh
```

æµè§ˆå™¨è®¿é—® <https://master:16010>
![](https://img.makis-life.cn/images/20251210053415919.png?x-oss-process=style/yasuo)
å¯ä»¥çœ‹è§æœ‰ä¸‰ä¸ª slave èŠ‚ç‚¹

**jps**
![](https://img.makis-life.cn/images/20251210053415920.png?x-oss-process=style/yasuo)
![](https://img.makis-life.cn/images/20251210053415921.png?x-oss-process=style/yasuo)

#### æµ‹è¯• HBase

```bash
# æŸ¥çœ‹è¿›ç¨‹
jps
# Masteråº”è¯¥çœ‹åˆ°: HMaster
# Slaveåº”è¯¥çœ‹åˆ°: HRegionServer

# è¿›å…¥HBase Shell
hbase shell

# åˆ›å»ºæµ‹è¯•è¡¨
create 'test', 'cf'

# æ’å…¥æ•°æ®
put 'test', 'row1', 'cf:name', 'zhangsan'
put 'test', 'row1', 'cf:age', '25'

# æŸ¥è¯¢æ•°æ®
scan 'test'
get 'test', 'row1'

# é€€å‡º
exit
```

![](https://img.makis-life.cn/images/20251210053415922.png?x-oss-process=style/yasuo)
ä¸Šå›¾å¯ä»¥çœ‹è§ï¼Œstatus æ˜¾ç¤ºä¸€ä¸ªæ´»è·ƒçš„ master èŠ‚ç‚¹ï¼Œä¸‰ä¸ª server èŠ‚ç‚¹ã€‚

åˆ›å»ºè¡¨åï¼Œåœ¨ web ç•Œé¢å¯ä»¥çœ‹è§æ–°å»ºçš„è¡¨
![](https://img.makis-life.cn/images/20251210053415923.png?x-oss-process=style/yasuo)

> [!note] ğŸ‰
> è‡³æ­¤ï¼ŒHBase é›†ç¾¤æ­å»ºæˆåŠŸï¼

### å®‰è£… Hive

#### ä¸‹è½½

å‰å¾€[é˜¿é‡Œäº‘é•œåƒç«™](https://mirrors.aliyun.com/apache/hive/?spm=a2c6h.25603864.0.0.23f63123S7PuMA)æˆ– wget ä¸‹è½½

```bash
wget https://mirrors.aliyun.com/apache/hive/hive-4.2.0/apache-hive-4.2.0-bin.tar.gz
```

#### å®‰è£… Hive

```bash
tar -xzf å®‰è£…åŒ…
sudo mv å®‰è£…åŒ… /usr/local/hive
sudo chown -R hadoop:hadoop /usr/local/hive
```

![](https://img.makis-life.cn/images/20251210053415924.png?x-oss-process=style/yasuo)

åˆ é™¤å’Œ hadoop é‡å¤çš„ slf4j åŒ…

```bash
rm $HIVE_HOME/lib/log4j-slf4j-impl-2.24.3.jar
```

æ£€æŸ¥ hive å’Œ hadoop çš„ `guava` åŒ…ï¼Œåˆ é™¤ä½ç‰ˆæœ¬å¹¶æŠŠé«˜ç‰ˆæœ¬å¤åˆ¶è¿‡å»

```bash
ls $HIVE_HOME/lib | grep guava
ls $HADOOP_HOME/share/hadoop/common/lib/ | grep guava
```

![](https://img.makis-life.cn/images/20251210053415925.png?x-oss-process=style/yasuo)
è¿™é‡Œ hadoop çš„ç‰ˆæœ¬æ¯” hive é«˜ï¼Œæ‰€ä»¥åˆ é™¤ hiveï¼Œå¹¶æŠŠ hadoop çš„ guava å¤åˆ¶è¿‡å»
![](https://img.makis-life.cn/images/20251210053415926.png?x-oss-process=style/yasuo)

æ›´æ–°ç¯å¢ƒå˜é‡
ç¼–è¾‘`~/.profile~

```bash
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin
```

ç›®å‰ profile çŠ¶æ€
![](https://img.makis-life.cn/images/20251210053415927.png?x-oss-process=style/yasuo)

åº”ç”¨ profile

```bash
source ~/.profile
```

#### åˆ†å‘å¹¶æ£€éªŒ`profile`

```bash
./run.sh slaves scp ~/.profile ~/.profile
./run.sh slaves ssh "source ~/.profile && echo $HIVE_HOME"
```

![](https://img.makis-life.cn/images/20251210053415928.png?x-oss-process=style/yasuo)

#### é…ç½® hive-site

**ä¿®æ”¹`/usr/local/hive/conf`ä¸‹çš„ hive-site.xml**
è¿›å…¥ hive é…ç½®æ–‡ä»¶å¤¹ï¼ŒæŠŠ`hive-default.xml.template`æ‹·è´ä¸€ä»½ä¸º`hive-default.xml`
ç„¶åæ–°å»ºä¸€ä¸ª`hive-site.xml`æ–‡ä»¶
![](https://img.makis-life.cn/images/20251210053415929.png?x-oss-process=style/yasuo)

å†…å®¹å¦‚ä¸‹

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
    <description>username to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
    <description>password to use against metastore database</description>
  </property>
</configuration>
```

åœ¨`nvim $HADOOP_HOME/etc/hadoop/core-site.xml`æ–°å¢

```xml
<property>
  <name>hadoop.proxyuser.hadoop.hosts</name>
  <value>*</value>
</property>
<property>
  <name>hadoop.proxyuser.hadoop.groups</name>
  <value>*</value>
</property>
```

ä¸Šé¢ hadoop å¯¹åº”ç”¨æˆ·åã€‚
é‡å¯ hdfs

```bash
stop-all.sh && sleep 60 && start-all.sh
```

#### Master å®‰è£… MySQL

> ä¹Ÿå¯åœ¨ Slave å®‰è£…ï¼Œåœ¨ä¸Šè¿°çš„ hive-site ä¸­é…ç½®å¥½ jdbc å³å¯

æ›´æ–°è½¯ä»¶åŒ…

```bash
sudo apt update
```

å®‰è£… mysql

```bash
sudo apt install mysql-server -y
```

ä¸‹è½½ jdbc

```bash
wget https://mirrors.aliyun.com/mysql/Connector-J/mysql-connector-java-8.0.29.tar.gz
```

è§£å‹å¹¶å¤åˆ¶åˆ° hive åº“

```bash
tar -xzf mysql-connector-java-8.0.29.tar.gz
cp mysql-connector-java-8.0.29/mysql-connector-java-8.0.29.jar /usr/local/hive/lib
```

![](https://img.makis-life.cn/images/20251210053415930.png?x-oss-process=style/yasuo)

##### å¯åŠ¨å¹¶ç™»å½• mysql

```bash
sudo systemctl start mysql
```

##### æ£€æŸ¥ mysql çŠ¶æ€

```bash
sudo systemctl status mysql
```

![](https://img.makis-life.cn/images/20251210053415931.png?x-oss-process=style/yasuo)
å¯è§ mysql å¤„äº running çŠ¶æ€

##### ç™»å½• mysql

```bash
sudo mysql
```

æ–°å»º hive æ•°æ®åº“

```sql
CREATE DATABASE hive;
```

æ–°å»ºä¸€ä¸ªå…è®¸ localhost è¿æ¥çš„ hive ç”¨æˆ·ï¼Œå¹¶èµ‹äºˆå®ƒæ‰€æœ‰æ•°æ®åº“çš„æ‰€æœ‰è¡¨çš„æƒé™

```sql
CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive';
GRANT ALL PRIVILEGES ON *.* TO 'hive'@'localhost' WITH GRANT OPTION;
FLUSH PRIVILEGES;
```

è¿™é‡Œçš„è´¦å·å¯†ç ï¼Œè¦å’Œ`hive-site.xml`å¯¹åº”

#### åˆå§‹åŒ–å…ƒæ•°æ®åº“

```bash
cd $HIVE_HOME/bin
./schematool -dbType mysql -initSchema
```

![](https://img.makis-life.cn/images/20251210053415932.png?x-oss-process=style/yasuo)

#### å¯åŠ¨ hive

> éœ€è¦å…ˆå¯åŠ¨ hdfs

```bash
hive
```

![](https://img.makis-life.cn/images/20251210053415933.png?x-oss-process=style/yasuo)
æˆåŠŸè¿›å…¥ beeline
é€€å‡ºï¼š`Ctrl + C`

##### æ£€éªŒ Hive æ˜¯å¦æ­£ç¡®æ­å»º

åˆ›å»ºæ–‡ä»¶

```
vim ~/test
```

```
1,jessie
2,winster
3,john
```

è¿›å…¥ hive äº¤äº’ç•Œé¢

```
hive
```

è¿æ¥ hive

```hive
!connect jdbc:hive2://localhost:10000
# ç„¶åè¾“å…¥hive-siteé‡Œé¢çš„è´¦å·å¯†ç 
```

![](https://img.makis-life.cn/images/20251210053415934.png?x-oss-process=style/yasuo)

åˆ›å»ºè¡¨æ ¼

```hive
create table test(
   > id int,name string
   > )
   > row format delimited
   > fields terminated by ',';
```

æ‰§è¡ŒæˆåŠŸ
![](https://img.makis-life.cn/images/20251210053415935.png?x-oss-process=style/yasuo)

æŸ¥çœ‹è¡¨æ ¼

```sql
SHOW TABLES;
DESCRIBE test;
```

![](https://img.makis-life.cn/images/20251210053415936.png?x-oss-process=style/yasuo)
![](https://img.makis-life.cn/images/20251210053415937.png?x-oss-process=style/yasuo)

åŠ è½½åˆšæ‰çš„ test æ–‡ä»¶

```sql
LOAD DATA LOCAL INPATH '/home/hadoop/test' INTO TABLE test;
```

æŸ¥çœ‹æ˜¯å¦å¯¼å…¥æˆåŠŸ

```sql
SELECT * FROM test;
```

![](https://img.makis-life.cn/images/20251210053415938.png?x-oss-process=style/yasuo)

> [!note] ğŸ‰
> è‡³æ­¤ hive å®‰è£…å®Œæˆ

### å®‰è£… scala

#### ä¸‹è½½

[é˜¿é‡Œäº‘é•œåƒç«™](https://mirrors.aliyun.com/macports/distfiles/scala/)æˆ– wget ä¸‹è½½ scala

```bash
wget https://mirrors.aliyun.com/macports/distfiles/scala/scala-2.13.16.tgz?spm=a2c6h.25603864.0.0.1cd95fc6zmb1CB
```

#### å®‰è£…

```bash
tar -xzf scalaå®‰è£…åŒ…
sudo mv scala(tab) /usr/local/scala
sudo chown -R hadoop:hadoop /usr/local/scala
```

æ›´æ–° profile

```bash
# SCALA
export SCALA_HOME=/usr/local/scala
export PATH=$SCALA_HOME/bin:$PATH
```

ç›®å‰ profile çŠ¶æ€
![](https://img.makis-life.cn/images/20251210053415939.png?x-oss-process=style/yasuo)
`source ~/.profile` å¹¶åˆ†å‘

#### åˆ†å‘ Scala

```bash
./run.sh slaves scp $SCALA_HOME ~
./run.sh slaves ssh "sudo mv ~/scala /usr/local/scala"
```

![](https://img.makis-life.cn/images/20251210053415940.png?x-oss-process=style/yasuo)

### å®‰è£… Spark

#### ä¸‹è½½ spark

[é˜¿é‡Œäº‘é•œåƒç«™](https://mirrors.aliyun.com/apache/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz)
æˆ– wget ä¸‹è½½

```bash
wget https://mirrors.aliyun.com/apache/spark/spark-4.0.1/spark-4.0.1-bin-hadoop3.tgz
```

è§£å‹å¹¶å®‰è£…

```bash
tar -xzf spark(tab)
sudo mv spark(tab) /usr/local/spark
sudo chown -R hadoop:hadoop /usr/local/spark
```

é…ç½® spark

```bash
cd /usr/local/spark/conf
cp spark-env.sh.template spark-env.sh
vim spark-env.sh
```

å†…å®¹:

```bash
#!/usr/bin/env bash

# ----------------------------
# Java & Scala ç¯å¢ƒ
# ----------------------------
export JAVA_HOME=/usr/lib/jvm/jdk21
export SCALA_HOME=/usr/local/scala
export PATH=$JAVA_HOME/bin:$SCALA_HOME/bin:$PATH

# ----------------------------
# Hadoop ç¯å¢ƒ
# ----------------------------
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

# ----------------------------
# Spark Master é…ç½®
# ----------------------------
export SPARK_MASTER_HOST=master        # Master ä¸»æœºåæˆ– IP
export SPARK_MASTER_PORT=7077          # Master é€šä¿¡ç«¯å£
export SPARK_MASTER_WEBUI_PORT=8080    # Master Web UI ç«¯å£
export SPARK_DAEMON_MEMORY=1g          # Masterã€Worker å’Œ History Server è‡ªèº«å ç”¨å†…å­˜

# ----------------------------
# Spark Worker é…ç½®
# ----------------------------
export SPARK_WORKER_CORES=4            # æ¯ä¸ª Worker åˆ†é…çš„ CPU æ ¸æ•°
export SPARK_WORKER_MEMORY=2g          # æ¯ä¸ª Worker åˆ†é…çš„æ€»å†…å­˜
export SPARK_WORKER_DIR=/data/spark    # Worker ä¸´æ—¶ç›®å½•
export SPARK_WORKER_PORT=7078
export SPARK_WORKER_WEBUI_PORT=8081

# ----------------------------
# Spark é€šç”¨èµ„æºé…ç½®
# ----------------------------
export SPARK_LOCAL_DIRS=/data/spark/local     # Shuffle å’Œ RDD å­˜å‚¨ç›®å½•
export SPARK_CONF_DIR=$SPARK_HOME/conf
export SPARK_LOG_DIR=$SPARK_HOME/logs
export SPARK_PID_DIR=/tmp

# ----------------------------
# Spark Driver / Executor é…ç½®
# ----------------------------
export SPARK_EXECUTOR_CORES=2
export SPARK_EXECUTOR_MEMORY=2g
export SPARK_DRIVER_MEMORY=1g

# ----------------------------
# Beeline é…ç½®
# ----------------------------
export SPARK_BEELINE_MEMORY=1g
```

ä¿®æ”¹ slaves æ–‡ä»¶

```bash
cp workers.template workers
vim workers
```

![](https://img.makis-life.cn/images/20251210053415941.png?x-oss-process=style/yasuo)

#### æ›´æ–°ç¯å¢ƒå˜é‡

```bash
vim ~/.profile
```

æ–°å¢

```bash
export SPARK_HOME=/usr/local/spark
export PATH=$SPARK_HOME/bin:$PATH
```

`source ~/.profile`

#### åˆ†å‘ spark å’Œ profile

```bash
./run.sh slaves scp $SPARK_HOME ~
./run.sh slaves scp ~/.profile ~/.profile
./run.sh slaves ssh "sudo mv ~/spark /usr/local/spark"
```

![](https://img.makis-life.cn/images/20251210053415942.png?x-oss-process=style/yasuo)
![](https://img.makis-life.cn/images/20251210053415943.png?x-oss-process=style/yasuo)

#### å¯åŠ¨ spark

```bash
spark-shell
```

å¯ä»¥çœ‹è§æ¬¢è¿ç•Œé¢
![](https://img.makis-life.cn/images/20251210053415944.png?x-oss-process=style/yasuo)

#### ç®€å•æµ‹è¯• Spark

è¿è¡Œä¸€é¡¹ç®€å•çš„æµ‹è¯•

```spark
// è¯»å–æ–‡ä»¶ä¸ºRDD
val textFile = sc.textFile("file:///usr/local/spark/README.md")

// è·å–RDDçš„ç¬¬ä¸€è¡Œå†…å®¹
textFile.first()
// res0: String = "ç¬¬ä¸€è¡Œå†…å®¹"

// è·å–RDDæ‰€æœ‰é¡¹çš„è®¡æ•°
textFile.count()
// res1: Long = æ–‡ä»¶æ€»è¡Œæ•°

// æŠ½å–å«æœ‰ "Spark" çš„è¡Œï¼Œè¿”å›ä¸€ä¸ªæ–°çš„RDD
val lineWithSpark = textFile.filter(line => line.contains("Spark"))

// ç»Ÿè®¡æ–°çš„RDDçš„è¡Œæ•°
lineWithSpark.count()
// res2: Long = å« "Spark" çš„è¡Œæ•°

// æ‰¾å‡ºæ–‡æœ¬ä¸­æ¯è¡Œçš„æœ€å¤šå•è¯æ•°
textFile.map(line => line.split(" ").length).reduce((a, b) => if (a > b) a else b)
// res3: Int = æ¯è¡Œçš„æœ€å¤§å•è¯æ•°

// é€€å‡º spark-shell
:quit
```

![](https://img.makis-life.cn/images/20251210053415945.png?x-oss-process=style/yasuo)

> [!note] ğŸ‰
> è‡³æ­¤ï¼ŒSpark å®‰è£…å®Œæˆï¼

**è‡³æ­¤ï¼Œå®Œå…¨åˆ†å¸ƒå¼æ­å»ºå®Œæˆ! ğŸ‰**

## é—®é¢˜ä¸è§£å†³

#### é€šä¿¡

é›†ç¾¤èµ·å§‹é˜¶æ®µï¼Œå°ç»„æˆå‘˜æˆ· ping å‡ºç°é—®é¢˜ï¼Œé€šè¿‡æ›´æ¢ç½‘ç»œç¯å¢ƒï¼Œæ£€æŸ¥ openssh-server å®‰è£…æƒ…å†µï¼Œæ’æŸ¥åå‘ç°æ˜¯ ufw é˜²ç«å¢™å±è”½äº† 22 å…¥å£ã€‚
é€šè¿‡

```bash
sudo ufw allow 22/tcp
```

å¯è§£å†³ã€‚

### jdk ç‰ˆæœ¬é—®é¢˜

èµ·åˆæŒ‰è¯¾ç¨‹è¦æ±‚é‡‡ç”¨ 1.8u202ï¼Œä½†åœ¨è¿è¡Œ HBase æ—¶å‘ç°è¦æ±‚ jdk11 ä»¥ä¸Šï¼Œåä½¿ç”¨ jdk11ã€‚å®‰è£… Hive æ—¶å‘ç° hive è¿è¡Œéœ€è¦ jdk21ï¼Œåå®‰è£… jdk21ã€‚
æ›´æ¢ jdk ç‰ˆæœ¬æ—¶åº”è®°å¾—åŒæ—¶æ›´æ”¹ profileï¼Œhadoopï¼Œyarnï¼Œhbaseï¼Œspark çš„ jdk åœ°å€

### ç©ºé—´ä¸è¶³

èµ·åˆè™šæ‹Ÿæœºå·²åˆ†é…å­˜å‚¨ä¸º 12GBï¼Œæ­å»ºé€”ä¸­å‘ç°æ— æ³•ä¼ å…¥å®‰è£…åŒ…ï¼Œé€šè¿‡`df -h`å‘ç°å¯ç”¨ç©ºé—´å‰©ä½™ä¸åˆ° 300MBã€‚
ä½†æ˜¯åˆ›å»ºè™šæ‹Ÿæœºæ—¶åˆ†é…çš„ç¡¬ç›˜ä¸º 25GBï¼Œæ’æŸ¥åå‘ç°æœ‰ 12GB ä¸ºæœªåˆ†é…å­˜å‚¨ã€‚
æ‰§è¡Œï¼š

```bash
sudo lvresize -l +100%FREE /dev/ubuntu-vg/ubuntu-lv
sudo resize2fs /dev/ubuntu-vg/ubuntu-lv
```

æŠŠä¸ºåˆ†é…å­˜å‚¨åˆ†é…å¥½ã€‚å¹¶ä¸”å†æ¬¡æ£€æŸ¥ hadoop web,å„è™šæ‹Ÿæœºçš„å­˜å‚¨ä¹Ÿéƒ½æ‰©å®¹äº†ã€‚

## å®éªŒæ€»ç»“

æ­¤æ¬¡å®éªŒå®Œæˆäº†åŸºäºå››å° Ubuntu è™šæ‹Ÿæœºçš„åˆ†å¸ƒå¼å¤§æ•°æ®ç¯å¢ƒæ­å»ºï¼ŒåŒ…å« ZooKeeperã€Hadoopï¼ˆHDFS + YARNï¼‰ã€HBaseã€Hiveã€Sparkã€Scala ä¸ OpenJDK çš„å®‰è£…ä¸è”è°ƒã€‚æŒæ¡äº†ä»å•æœºéƒ¨ç½²åˆ°å¤šèŠ‚ç‚¹é›†ç¾¤åˆ†å‘ã€é…ç½®ã€å¯åŠ¨ä¸éªŒè¯çš„å®Œæ•´æµç¨‹ï¼Œèƒ½å¤Ÿç‹¬ç«‹å¤ç°å®éªŒç¯å¢ƒå¹¶è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹ã€‚

### ä¸»è¦æ”¶è·ä¸èƒ½åŠ›æå‡

1. ç¯å¢ƒéƒ¨ç½²ä¸è‡ªåŠ¨åŒ–åˆ†å‘ï¼šç†Ÿç»ƒä½¿ç”¨`/etc/hosts`ï¼ˆhosts æ–‡ä»¶ï¼‰é…ç½®ä¸»æœºåè§£æã€ç¼–å†™å¹¶ä½¿ç”¨ run.sh è„šæœ¬å®ç°å¯¹å¤šèŠ‚ç‚¹çš„`ssh`ï¼ˆSSHï¼‰è¿œç¨‹æ‰§è¡Œä¸`scp`ï¼ˆSCPï¼‰åˆ†å‘ï¼Œæå‡éƒ¨ç½²æ•ˆç‡ã€‚
2. å…å¯†ä¸æƒé™ç®¡ç†ï¼šå®Œæˆ SSH å…å¯†ç™»å½•ï¼ˆSSH passwordless loginï¼‰ä¸ sudo æ— å¯†ç é…ç½®ï¼ˆsudoersï¼‰ï¼Œç®€åŒ–é›†ç¾¤ç®¡ç†æµç¨‹ã€‚
3. è½¯ä»¶å®‰è£…ä¸ç¯å¢ƒå˜é‡ç®¡ç†ï¼šæŒæ¡ OpenJDKã€Scalaã€Hadoopã€Sparkã€HBaseã€Hive çš„å®‰è£…ã€è§£å‹ã€ç§»åŠ¨ä¸`~/.profile`ï¼ˆprofileï¼‰ç¯å¢ƒå˜é‡é…ç½®ï¼Œå¹¶å°†é…ç½®åŒæ­¥è‡³æ‰€æœ‰èŠ‚ç‚¹ã€‚
4. ç»„ä»¶é…ç½®ä¸è”è°ƒï¼šèƒ½å¤Ÿé…ç½® ZooKeeper é›†ç¾¤ï¼ˆmyid ä¸ server.Xï¼‰ã€Hadoop çš„ core-site/hdfs-site/mapred-site/yarn-siteã€HBase çš„ hbase-siteã€Hive çš„ hive-siteï¼ˆå« JDBC å…ƒæ•°æ®åº“ï¼‰ä»¥åŠ Spark çš„ spark-env ä¸ workersï¼ˆworkersï¼‰ã€‚
5. è°ƒè¯•ä¸é—®é¢˜è§£å†³èƒ½åŠ›ï¼šè§£å†³ç«¯å£/é˜²ç«å¢™ï¼ˆufwï¼‰é—®é¢˜ã€JDK ç‰ˆæœ¬ä¸ä¸€è‡´å¯¼è‡´çš„å…¼å®¹æ€§é—®é¢˜ã€ä¾èµ–åŒ…å†²çªï¼ˆå¦‚ guava/slf4jï¼‰ã€ç£ç›˜æ‰©å®¹ï¼ˆLVM resizeï¼‰ç­‰å¸¸è§æ•…éšœã€‚
6. é›†ç¾¤éªŒè¯ä¸ä½¿ç”¨ï¼šä¼šä½¿ç”¨`hadoop namenode -format`ã€`start-dfs.sh`ã€`start-yarn.sh`ã€`start-hbase.sh`ã€`zkServer.sh start`ç­‰å‘½ä»¤å¯åŠ¨æœåŠ¡ï¼Œå¹¶é€šè¿‡ Web UIï¼ˆNameNode/HBase Master/Sparkï¼‰ä¸`jps`ã€HBase Shellã€Hive(Beeline) ç­‰å·¥å…·éªŒè¯é›†ç¾¤å¥åº·ä¸åŠŸèƒ½ã€‚
7. å¤§æ•°æ®å·¥å…·ç†è§£ï¼šæ˜ç¡®å„ç»„ä»¶èŒè´£ä¸é€‚ç”¨åœºæ™¯ï¼Œèƒ½å¤Ÿé’ˆå¯¹æ•°æ®å­˜å‚¨ã€å®æ—¶è¯»å†™ä¸æ‰¹å¤„ç†ç­‰éœ€æ±‚é€‰æ‹©åˆé€‚å·¥å…·ã€‚
